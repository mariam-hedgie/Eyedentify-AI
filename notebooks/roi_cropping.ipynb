{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import mediapipe as mp\n",
    "from pathlib import Path  # for safer path joins if needed\n",
    "import pandas as pd\n",
    "\n",
    "# access utils if using shared code\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_crop(input_path, output_path, label):\n",
    "\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True, \n",
    "    refine_landmarks=True, \n",
    "    max_num_faces=1, \n",
    "    min_detection_confidence=0.5 # inc if too many fase detections\n",
    ")\n",
    "    LEFT_EYE_LANDMARKS = [463, 398, 384, 385, 386, 387, 388, 466, 263, 249, 390, 373, 374, 380, 381, 382, 362]\n",
    "    RIGHT_EYE_LANDMARKS = [33, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145, 144, 163, 7]\n",
    "    LEFT_IRIS_LANDMARKS = [474, 475, 477, 476]\n",
    "    RIGHT_IRIS_LANDMARKS = [469, 470, 471, 472]\n",
    "\n",
    "    for file in os.listdir(input_path):\n",
    "        img_path = os.path.join(input_path, file)\n",
    "\n",
    "        try:\n",
    "            # loads the image\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            if img is None or len(img.shape) != 3 or img.shape[2] != 3:\n",
    "                raise Exception\n",
    "            \n",
    "            # convert img to RGB for mediapipe\n",
    "            # opencv default is BGR\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            results = face_mesh.process(img_rgb)\n",
    "\n",
    "            if not results.multi_face_landmarks:\n",
    "                print(f\"No face detected: {file}\")\n",
    "                continue\n",
    "            \n",
    "            # get actual positions on img\n",
    "            h, w, _ = img.shape\n",
    "            landmarks = results.multi_face_landmarks[0]\n",
    "            eye_points = []\n",
    "            for idx in LEFT_EYE_LANDMARKS + RIGHT_EYE_LANDMARKS:\n",
    "                x = int(landmarks.landmark[idx].x * w)  # scale x to image width\n",
    "                y = int(landmarks.landmark[idx].y * h)  # scale y to image height\n",
    "                eye_points.append((x, y))\n",
    "            \n",
    "            x_coords, y_coords = zip(*eye_points)  # separates xs and ys\n",
    "\n",
    "            # find min and max x and y for bounding rectangle\n",
    "            x_min, x_max = max(min(x_coords), 0), min(max(x_coords), w)\n",
    "            y_min, y_max = max(min(y_coords), 0), min(max(y_coords), h)\n",
    "\n",
    "            roi = img[y_min:y_max, x_min:x_max]  # Crop using the box\n",
    "            roi_resized = cv2.resize(roi, (224, 224))  # Resize to model input size\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
